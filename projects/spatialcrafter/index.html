<html lang="en-GB">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SpatialCrafter</title>
    <meta name="description" content="We've presented Clarity, a minimalist and elegant website template for AI research.">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <meta name="robots" content="all">
    <meta content="en_EN" property="og:locale">
    <meta content="website" property="og:type">
    <meta content="https://shikun.io/projects/clarity" property="og:url">
    <meta content="Clarity" property="og:title">
    <meta content="Website Template for AI Research" property="og:description">

    <link rel="stylesheet" type="text/css" media="all" href="assets/stylesheets/main_free.css" />
    <link rel="stylesheet" type="text/css" media="all" href="clarity/clarity.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/foundation.min.css">
    <link href="assets/fontawesome-free-6.6.0-web/css/all.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/img-comparison-slider@8/dist/styles.css"/>
    <script defer src="https://cdn.jsdelivr.net/npm/img-comparison-slider@8/dist/index.js"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            "HTML-CSS": {
              scale: 95,
              fonts: ["Gyre-Pagella"],
              imageFont: null,
              undefinedFamily: "'Arial Unicode MS', cmbright"
            },
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                processEscapes: true
              }
          });
    </script>
    <script type="text/javascript"
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
</head>

<body>
    <!-- Title Page -->
    <!-- Dark Theme Example: Change the background colour dark and change the following div "blog-title" into "blog-title white". -->
    <div class="container blog" id="first-content" style="background-color: #E0E4E6;">
        <!-- If you don't have a project cover: Change "blog-title" into "blog-title no-cover"  -->
        <div class="blog-title no-cover">
            <div class="blog-intro">
                <div>
                    <h1>SpatialCrafter: Unleashing the Imagination of Video Diffusion Models for Scene Reconstruction from Limited Observations</h1>
                    
                    <p class="author">
                        Anonymous Authors
                    </p>
                    <!-- Using FontAwesome Pro -->
                    <!-- <div class="info">
                        <div>
                            <a href="https://arxiv.org" class="button icon" style="background-color: rgba(255, 255, 255, 0.3)"> Paper <i class="far fa-book-open"></i></a> &nbsp;&nbsp; 
                            <a href="https://github.com" class="button icon" style="background-color: rgba(255, 255, 255, 0.3)">Code <i class="far fa-code"></i></a>  &nbsp;&nbsp; 
                            <a href="https://www.microsoft.com/en-gb/microsoft-365/powerpoint" class="button icon" style="background-color: rgba(255, 255, 255, 0.3);">Slides <i class="far fa-presentation"></i></a>  &nbsp;&nbsp; 
                            <a href="https://huggingface.co/spaces" class="button icon" style="background-color: rgba(255, 255, 255, 0.3)">Demo <i class="fa-light fa-face-smiling-hands"></i></a>
                        </div>
                    </div> -->

                    <!-- Using FontAwesome Free -->
                    <!-- <div class="info">
                        <div>
                            <a href="https://arxiv.org" class="button icon" style="background-color: rgba(255, 255, 255, 0.2)"> Paper <i class="fa-solid fa-book-open"></i></a> &nbsp;&nbsp; 
                            <a href="https://github.com" class="button icon" style="background-color: rgba(255, 255, 255, 0.2)">Code <i class="fa-solid fa-code"></i></a>  &nbsp;&nbsp; 
                            <a href="https://www.microsoft.com/en-gb/microsoft-365/powerpoint" class="button icon" style="background-color: rgba(255, 255, 255, 0.2);">Slides <i class="fa-regular fa-file-powerpoint"></i></a> &nbsp;&nbsp; 
                            <a href="https://huggingface.co/spaces/" class="button icon" style="background-color: rgba(255, 255, 255, 0.2)">Demo <i class="fa-solid fa-laptop-code"></i></a> 
                        </div>
                    </div> -->
                </div>
            </div>
        </div>
    </div>


    <div class="container blog main first" id="blog-main">
        <h1 >
            Introduction
        </h1>
        <p class='text'>
            Novel view synthesis (NVS) boosts immersive experiences in computer vision and graphics. Existing techniques, though progressed, rely on dense multi-view observations, restricting their application. 
            This work takes on the challenge of reconstructing photorealistic 3D scenes from sparse or single-view inputs.
            We introduce SpatialCrafter, a novel framework that leverages the rich knowledge in video diffusion models to generate plausible additional observations, thus enhancing the reconstruction quality in both interpolation and extrapolation settings. 
            Our approach applies ray embeddings for precise camera parameterization and an epipolar attention mechanism for better 3D consistency in generated video frames.
            To address the scale ambiguity between different scene datasets, we adopt a unified scale estimator to calibrate the datasets to ensure robust performance when jointly trained on multiple datasets.
            Furthermore, we developed a robust reconstruction framework that combines monocular depth priors and dense stereo priors for geometric initialization, and further improved the robustness of reconstruction from generated video frames via uncertainty-aware optimization.
            Extensive experiments show our method enhances sparse view reconstruction and restores the realistic appearance of 3D scenes. 
        </p>
    </div>


    <div class="container blog main">
        <h1 >
            Our Pipeline
        </h1>
        <h1>

        </h1>
        <img src="assets\figures\pipeline.png">
        <p class='text'>
            Our generative reconstruction pipeline consists of three parts: trajectory planning, camera-controlled video generation, and robust reconstruction. 
            First, we set the exploration path based on the input views. In the video generation module, ray embedding is used to parameterize the camera, and a cross-attention mechanism with epipolar constraints is introduced to improve the 3D consistency of the generated video.
            The robust 3D scene reconstruction pipeline integrates an uncertainty-aware optimization process, which uses monocular and stereo priors to obtain the aligned canonical point cloud for geometric initialization, thereby improving the quality of the final 3D reconstruction.   
        </p>
    </div>
   
    <div class="container blog main gray">
        <div class="slide-menu">
            <ul class="dots" id="slide-menu">
                <li class="dot active"></li>
                <li class="dot"></li>
                <li class="dot"></li>
                <li class="dot"></li>
            </ul>
        </div>
       
        <div class="slide-content", style="display: block;">
            <video loop playsinline muted autoplay src="assets/videos/flower.mp4" style="width: 100%"> </video>
        </div>

        <div class="slide-content", style="display: none;">
            <video loop playsinline muted autoplay src="assets/videos/demo_12_view.mp4" style="width: 100%"> </video>
        </div>

        <div class="slide-content", style="display: none;">
            <video loop playsinline muted autoplay src="assets/videos/demo_13_view.mp4" style="width: 100%"> </video>
        </div>

        <div class="slide-content", style="display: none;">
            <video loop playsinline muted autoplay src="assets/videos/diffusion.mp4" style="width: 100%"> </video>
        </div>


        <p class="caption">
            The videos show interpolations between hand-picked latent points in several datasets. Observe again how the textural detail appears fixed in the StyleGAN-2 result, but transforms smoothly with the rest of the scene in the alias-free StyleGAN-3.
        </p>
    </div>

    <div class="container blog main">
        <h2>
            Auto Slideshow Display
        </h2>
        <p class="text">
            Alternatively, the Auto Slideshow Display feature enables readers to enjoy a large array of visual elements through an automated, slideshow-like presentation. Users can also navigate through the slideshow manually with "Left" and "Right" buttons. Below is an example using videos generated in <a href="https://mardini-vidgen.github.io/">MarDini</a>.
        </p>
        <!-- 
        1. You may add another row of visual elements by simply adding a video element in each "slider-item" div. Correspondingly, you need to change the following in the scss file (under Slideshow Control): height: 440px into 440px * num_rows. 
        2. You may also change the fixed image size by changing the following:
            a. scss: .slider-item width: 400px -> changed width; 
            b. scss: height: 440px -> changed width + padding_bottom;
            c. javascript: item.style.left = `${(i-1) * 440}px`) -> changed width + padding_left
        -->
    </div>
    <div class="container blog max gray">
        <div class="slideshow">
            <div class="navigation">
                <!-- Using FontAwesome Pro -->
                <!-- <a class="button icon" id="prev_btn"><i class="fa-solid fa-left" ></i></a>
                <a class="button icon" id="next_btn"><i class="fa-solid fa-right"></i></a> -->
                <!-- Using FontAwesome Free -->
                <a class="button icon" id="prev_btn"><i class="fa-solid fa-arrow-left"></i></a>
                <a class="button icon" id="next_btn"><i class="fa-solid fa-arrow-right"></i></a>
            </div>
            <div class="slider">
                <div class="slider-item">
                    <video loop playsinline muted autoplay src="assets/videos/demo_12_view_converted.mp4"></video>
                </div>
                <div class="slider-item">
                    <video loop playsinline muted autoplay src="assets/videos/demo_13_view.mp4"></video>
                </div>
                <div class="slider-item">
                    <video loop playsinline muted autoplay src="assets/videos/2.mp4"></video>
                </div>
                <div class="slider-item">
                    <video loop playsinline muted autoplay src="assets/videos/flower.mp4"></video>
                </div>
                <div class="slider-item">
                    <video loop playsinline muted autoplay src="assets/videos/diffusion.mp4"></video>
                </div>
            </div>
        </div>
    </div>



    <!-- Footer Page -->
    <footer>
        <div class="container">
            <p>
                This website is built on the <a href="https://shikun.io/projects/clarity">Clarity Template</a>, designed by <a href="https://shikun.io/">Shikun Liu</a>.
            </p>
        </div>    
    </footer>
    

    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script src="clarity/clarity.js"></script>    
    <script src="assets/scripts/main.js"></script>    
    </html>
</body>